# V5.5: Tree-Based Model Inference in Rust

## Overview

Implement Rust inference for trained sklearn tree-based models (Decision Trees, Random Forests, Gradient Boosted) as Tier 1 agents. Each agent evaluates all symbols independently, buying/selling based on configurable probability thresholds.

## Scope

**Model types supported:**
- **Decision Tree** - single classification tree (loaded from JSON)
- **Random Forest** - ensemble of classification trees, predictions averaged
- **Gradient Boosted** - staged ensemble of regression trees with learning rate

**Agent types:** 3 agent classes
- `DecisionTreeAgent` - single Decision Tree
- `RandomForestAgent` - Random Forest ensemble
- `GradientBoostedAgent` - Gradient Boosted ensemble

**Existing trained models** (in `models/` folder):
- `shallow_decision_tree.json`, `medium_decision_tree.json`
- `small_random_forest.json`, `large_random_forest.json`
- `fast_gradient_boosted.json`, `slow_gradient_boosted.json`

---

## Design Decisions

### 5.3 Traits: NOT Implemented

The 5.3 spec proposed these traits but they were **not built**:
```rust
// PLANNED but NOT implemented:
pub trait FeatureExtractor: Send + Sync { ... }
pub struct FeatureContext<'a> { ... }
pub trait MlModel: Send + Sync { fn predict(&self, features: &[f64]) -> f64; }
```

**Actual implementation:**
- `MarketFeatures::extract()` - concrete function taking explicit params
- `AgentFeatures::extract()` - concrete function with `AgentFeatureContext`
- No `MlModel` trait exists

### Data Access Gap

| System | Indicator Access |
|--------|-----------------|
| Recording (`EnrichedData`) | `HashMap<String, f64>` - `"SMA_8"`, `"RSI_8"` |
| Agents (`StrategyContext`) | `IndicatorType` enum - `Sma(8)`, `Rsi(8)` |

**Solution:** TreeAgent extracts all 42 features directly from `StrategyContext`. No per-agent computation - everything is shared.

### Shared Feature Architecture (Performance)

All 42 features are computed **once per tick per symbol** and shared across ALL agents:

| Feature Group | Count | Source | Computation Per Symbol |
|---------------|-------|--------|------------------------|
| Mid price | 1 | `ctx.mid_price(symbol)` | O(1) - order book read |
| Price changes | 12 | `ctx.price_change(symbol, period)` | 12 divisions |
| Log returns | 12 | `ctx.log_return(symbol, period)` | 12 ln() calls |
| Indicators | 13 | `ctx.get_indicator(symbol, type)` | Already computed |
| News features | 4 | `ctx.events`, `ctx.fair_value()` | O(active_events) |

**No per-agent PriceHistory.** Price changes and log returns are computed in a shared `PriceSnapshot` alongside `IndicatorSnapshot`.

### When Is PriceSnapshot Computed?

**Option A: Always (like IndicatorSnapshot)**
- Computed every tick for all symbols in `build_price_snapshot()`
- Cost: ~24 arithmetic ops × num_symbols per tick
- Benefit: Always available, no conditional logic
- Downside: Wasted if no agents need it

**Option B: On-demand (lazy)**
- Only computed when first agent requests `ctx.price_change()`
- Cached for remainder of tick
- Benefit: Zero cost if no tree agents
- Downside: Adds conditional/caching complexity

**Recommendation: Option A** - the cost is trivial (24 ops/symbol) compared to indicator computation (SMA/EMA/RSI/MACD/BB/ATR over candle history). Keep it simple, compute unconditionally.

### PriceSnapshot Implementation

```rust
pub struct PriceSnapshot {
    tick: Tick,
    // Pre-computed for each symbol at lookback periods [1,2,3,4,6,8,12,16,24,32,48,64]
    price_changes: HashMap<Symbol, [f64; 12]>,
    log_returns: HashMap<Symbol, [f64; 12]>,
}

impl PriceSnapshot {
    pub fn price_change(&self, symbol: &Symbol, period_index: usize) -> Option<f64> {
        self.price_changes.get(symbol).map(|arr| arr[period_index])
    }

    pub fn log_return(&self, symbol: &Symbol, period_index: usize) -> Option<f64> {
        self.log_returns.get(symbol).map(|arr| arr[period_index])
    }
}
```

**Storage requirement:** Rolling buffer of 64 mid prices per symbol (the longest lookback). This is maintained in `MarketDataManager` alongside candles.

### Run Mode Transparency

The 42 features are **internal to agent decision-making** - not transmitted to TUI or server:

| Mode | Feature Computation | Output Contains Features? |
|------|--------------------|--------------------------|
| Headless | Once per tick (shared) | N/A - no output |
| TUI | Once per tick (shared) | No - SimUpdate has prices, trades, PnL |
| Server | Once per tick (shared) | No - TickData has prices, trades, PnL |

This is a pure internal optimization - transparent to all run modes.

---

## File Structure

```
crates/agents/src/tier1/ml/
├── mod.rs                # MlModel trait, module exports, type aliases
├── decision_tree.rs      # DecisionTree JSON loading + traversal
├── random_forest.rs      # RandomForest (array of trees, averaged predictions)
├── gradient_boosted.rs   # GradientBoosted (staged regression trees)
└── tree_agent.rs         # TreeAgent<M: MlModel> generic agent
```

---

## Core Types

### MlModel Trait (`mod.rs`)

```rust
/// Class probabilities: [p_sell, p_hold, p_buy] for classes [-1, 0, 1]
pub type ClassProbabilities = [f64; 3];

/// Trait for ML models that produce class probabilities.
pub trait MlModel: Send + Sync {
    /// Predict class probabilities from 42 market features.
    fn predict(&self, features: &[f64]) -> ClassProbabilities;

    /// Model name for logging.
    fn name(&self) -> &str;
}
```

**Rationale:** Return `[f64; 3]` probabilities instead of single f64 so agent can compare buy vs sell strength.

### DecisionTree (`decision_tree.rs`)

```rust
#[derive(Deserialize)]
struct TreeNode {
    feature: i32,       // -1 for leaf
    threshold: f64,
    left: i32,
    right: i32,
    value: Option<Vec<f64>>,  // [p_sell, p_hold, p_buy] for leaves
}

pub struct DecisionTree {
    name: String,
    nodes: Vec<TreeNode>,
}

impl DecisionTree {
    pub fn from_json<P: AsRef<Path>>(path: P) -> Result<Self, String>;
}

impl MlModel for DecisionTree {
    fn predict(&self, features: &[f64]) -> ClassProbabilities {
        // Traverse: feature[node.feature] <= threshold → left, else right
        // NaN → go left (conservative)
        // Return normalized leaf probabilities
    }
}
```

### RandomForest (`random_forest.rs`)

```rust
pub struct RandomForest {
    name: String,
    trees: Vec<Vec<TreeNode>>,  // Each tree is Vec<TreeNode>
}

impl MlModel for RandomForest {
    fn predict(&self, features: &[f64]) -> ClassProbabilities {
        // Traverse each tree, average probabilities
    }
}
```

### GradientBoosted (`gradient_boosted.rs`)

```rust
/// Node for regression trees (used in gradient boosting)
#[derive(Deserialize)]
struct RegressionNode {
    feature: i32,       // -1 for leaf
    threshold: f64,
    left: i32,
    right: i32,
    value: Option<f64>,  // Raw prediction value for leaves (not probabilities)
}

pub struct GradientBoosted {
    name: String,
    learning_rate: f64,
    n_classes: usize,
    stages: Vec<Vec<Vec<RegressionNode>>>,  // stages[stage_idx][class_idx] = tree nodes
}

impl MlModel for GradientBoosted {
    fn predict(&self, features: &[f64]) -> ClassProbabilities {
        // Initialize raw scores (one per class)
        let mut scores = vec![0.0; self.n_classes];

        // Accumulate predictions from each stage
        for stage in &self.stages {
            for (class_idx, tree) in stage.iter().enumerate() {
                let leaf_value = traverse_regression_tree(tree, features);
                scores[class_idx] += self.learning_rate * leaf_value;
            }
        }

        // Softmax to convert scores to probabilities
        softmax(&scores)
    }
}
```

**Key differences from classification trees:**
- Regression trees have scalar `value` in leaves (not probability arrays)
- Predictions are accumulated across stages with `learning_rate`
- Final scores converted to probabilities via softmax

### TreeAgentConfig (`tree_agent.rs`)

```rust
pub struct TreeAgentConfig {
    pub symbols: Vec<Symbol>,
    pub buy_threshold: f64,          // Configurable (e.g., 0.5, 0.6)
    pub sell_threshold: f64,         // Configurable
    pub order_size: u64,
    pub max_position_per_symbol: i64,
    pub initial_cash: Cash,
}
```

### TreeAgent (`tree_agent.rs`)

```rust
pub struct TreeAgent<M: MlModel> {
    id: AgentId,
    config: TreeAgentConfig,
    state: AgentState,
    model: M,
    // No PriceHistory - uses shared PriceSnapshot via ctx
}
```

---

## Decision Logic (per tick)

```
for each symbol in watched_symbols:
    1. Extract 42 features from StrategyContext (all shared, no per-agent computation)
    2. model.predict(features) → [p_sell, p_hold, p_buy]
    3. Store (symbol, p_buy, p_sell, mid_price)

Find best_buy:
    - highest p_buy where p_buy > buy_threshold AND position < max

Find best_sell:
    - highest p_sell where p_sell > sell_threshold AND position > 0

if best_sell.p_sell > best_buy.p_buy:
    generate sell order for best_sell.symbol
else if best_buy exists:
    generate buy order for best_buy.symbol
else:
    hold (no action)
```

---

## Feature Extraction from StrategyContext

The agent extracts 42 features from shared snapshots (zero per-agent computation):

```rust
// Lookback periods used for price changes and log returns
const LOOKBACKS: [u32; 12] = [1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64];

fn extract_features(symbol: &Symbol, ctx: &StrategyContext) -> [f64; 42] {
    let mut features = [NAN; 42];

    // 0: mid_price (from market)
    features[0] = ctx.mid_price(symbol).map(|p| p.to_float()).unwrap_or(NAN);

    // 1-12: price_change at lookbacks (from shared PriceSnapshot)
    for (i, &period) in LOOKBACKS.iter().enumerate() {
        features[1 + i] = ctx.price_change(symbol, period).unwrap_or(NAN);
    }

    // 13-24: log_return at same lookbacks (from shared PriceSnapshot)
    for (i, &period) in LOOKBACKS.iter().enumerate() {
        features[13 + i] = ctx.log_return(symbol, period).unwrap_or(NAN);
    }

    // 25-37: Technical indicators (from shared IndicatorSnapshot)
    features[25] = ctx.get_indicator(symbol, IndicatorType::Sma(8)).unwrap_or(NAN);
    features[26] = ctx.get_indicator(symbol, IndicatorType::Sma(16)).unwrap_or(NAN);
    features[27] = ctx.get_indicator(symbol, IndicatorType::Ema(8)).unwrap_or(NAN);
    features[28] = ctx.get_indicator(symbol, IndicatorType::Ema(16)).unwrap_or(NAN);
    features[29] = ctx.get_indicator(symbol, IndicatorType::Rsi(8)).unwrap_or(NAN);
    // MACD (30-32), BB (33-36), ATR (37) - see implementation notes below

    // 38-41: News features from ctx.events
    // ...

    features
}
```

**Note:** This is now a free function, not a method on TreeAgent. No `self` needed - all data comes from shared `ctx`.

### Indicator Mapping Notes

| Feature Index | Feature Name | IndicatorType |
|--------------|--------------|---------------|
| 25 | f_sma_8 | `Sma(8)` |
| 26 | f_sma_16 | `Sma(16)` |
| 27 | f_ema_8 | `Ema(8)` |
| 28 | f_ema_16 | `Ema(16)` |
| 29 | f_rsi_8 | `Rsi(8)` |
| 30 | f_macd_line | `Macd { fast: 8, slow: 16, signal: 4 }` component |
| 31 | f_macd_signal | (may need separate access) |
| 32 | f_macd_histogram | (may need separate access) |
| 33 | f_bb_upper | `BollingerBands { period: 12, std_dev_bp: 200 }` |
| 34 | f_bb_middle | (computed from bands) |
| 35 | f_bb_lower | (computed from bands) |
| 36 | f_bb_percent_b | (computed from bands + price) |
| 37 | f_atr_8 | `Atr(8)` |

**Implementation note:** Check if `IndicatorSnapshot` stores MACD/BB as single value or components. If single, may need to accept NaN for some features or extend indicator access.

---

## Files to Create/Modify

### Shared Feature Infrastructure (prerequisite)

| File | Action |
|------|--------|
| `crates/quant/src/price_snapshot.rs` | CREATE - PriceSnapshot struct |
| `crates/quant/src/lib.rs` | MODIFY - export PriceSnapshot |
| `crates/simulation/src/subsystems/market_data.rs` | MODIFY - add rolling price buffer, `build_price_snapshot()` |
| `crates/simulation/src/runner.rs` | MODIFY - call `build_price_snapshot()` in Phase 3 |
| `crates/agents/src/context.rs` | MODIFY - add `price_change()`, `log_return()` methods |

### Tree Agent Implementation

| File | Action |
|------|--------|
| `crates/agents/src/tier1/ml/mod.rs` | CREATE |
| `crates/agents/src/tier1/ml/decision_tree.rs` | CREATE |
| `crates/agents/src/tier1/ml/random_forest.rs` | CREATE |
| `crates/agents/src/tier1/ml/gradient_boosted.rs` | CREATE |
| `crates/agents/src/tier1/ml/tree_agent.rs` | CREATE |
| `crates/agents/src/tier1/mod.rs` | MODIFY - add `pub mod ml;` |
| `crates/agents/src/lib.rs` | MODIFY - re-export ml types |
| `crates/agents/Cargo.toml` | MODIFY - ensure `serde_json` dep |

---

## Integration

### Agent Creation

```rust
// In simulation setup or main.rs
let model = DecisionTree::from_json("models/shallow_decision_tree.json")?;
let config = TreeAgentConfig {
    symbols: vec!["ACME".into(), "BETA".into()],
    buy_threshold: 0.55,
    sell_threshold: 0.55,
    order_size: 50,
    max_position_per_symbol: 500,
    initial_cash: Cash::from_float(100_000.0),
};
let agent = TreeAgent::new(AgentId(100), model, config);
orchestrator.add_agent(Box::new(agent), tick);
```

### Type Aliases

```rust
pub type DecisionTreeAgent = TreeAgent<DecisionTree>;
pub type RandomForestAgent = TreeAgent<RandomForest>;
pub type GradientBoostedAgent = TreeAgent<GradientBoosted>;
```

---

## Testing

1. **Unit tests:**
   - `decision_tree.rs`: Load JSON, traverse known tree, handle NaN
   - `random_forest.rs`: Load JSON, verify averaging
   - `gradient_boosted.rs`: Load JSON, verify staged accumulation + softmax
   - `tree_agent.rs`: Mock model, test threshold logic

2. **Integration test:**
   - Load real model, run 1000 ticks, verify no panics

3. **Verification:**
   ```bash
   cargo test -p agents
   cargo run -- --ticks 1000  # with ML agents enabled
   ```

---

## Reference Files

- [comprehensive_features.rs](crates/storage/src/comprehensive_features.rs) - 42 feature names and order
- [traits.rs](crates/agents/src/traits.rs) - Agent trait
- [state.rs](crates/agents/src/state.rs) - AgentState
- [context.rs](crates/agents/src/context.rs) - StrategyContext (to be extended with price_change/log_return)
- [engine.rs](crates/quant/src/engine.rs) - IndicatorSnapshot (pattern for PriceSnapshot)

---

## Performance

### Feature Computation (per tick, ALL modes)

| Component | Per Symbol | Total (5 symbols) | Notes |
|-----------|------------|-------------------|-------|
| Price buffer update | 1 write | 5 writes | Append mid price to rolling buffer |
| Price changes | 12 divisions | 60 divisions | `(p_now - p_n) / p_n` |
| Log returns | 12 ln() | 60 ln() | `ln(p_now / p_n)` |
| **Subtotal (PriceSnapshot)** | ~24 ops | ~120 ops | **Trivial** |
| Indicators | Already paid | Already paid | SMA/EMA/RSI/MACD/BB/ATR |

**Conclusion:** PriceSnapshot adds ~24 arithmetic ops per symbol per tick. This is negligible compared to:
- Indicator computation (window operations over candle history)
- Order book operations
- Agent decision loops

### Model Inference (per agent)

| Model | Per Symbol | Notes |
|-------|------------|-------|
| Decision tree | O(depth) ~10-20 comparisons | Single tree traversal |
| Random forest | O(depth × n_trees) | 10-100 trees typical |
| Gradient boosted | O(depth × n_stages × n_classes) | 50-200 stages typical |

Target: <100µs per symbol (achievable for all model types)
