# V6.1: Full Feature Engineering

## Overview

Expand the V5 42-feature market schema to 55 centralized market features (42 base + 13 new). Each new feature is chosen for its **predictive signal** in trading decisions, not added mechanically. All features are market-level (shared across agents, cacheable).

**Requires**: Pre-V6 refactor complete (sections A-F: `FeatureExtractor` trait, `FeatureVec` cache, agent factory, gym API, schema-flexible recording)

**Note**: Base 42 features are kept stable (no trimming in V6.1). Trimming deferred to post-V6.2 after SHAP analysis provides empirical evidence. This preserves V5 model compatibility and V6.2 mixed-model support.

## Feature Design Principles

- **Signal over count**: More features is not better. Every feature must justify its existence with predictive value. Trim what doesn't work.
- **Distinct signals**: Each feature captures a different market regime (momentum, mean-reversion, liquidity, volatility, value). No redundant features.
- **Normalized scales**: Use ratios, basis points, and z-scores instead of raw prices. Trees don't need normalization, but V7.2 deep RL will — build the habit now.
- **No lookahead**: Only data available at decision time. Features computed from candles, indicators, and book state that exist before the agent acts.
- **No sunk-cost features**: No per-agent portfolio state (position, unrealized P&L). These encode behavioral biases (disposition effect, loss aversion) rather than predictive market signal. Position limits are enforced by `PositionValidator`. Risk management belongs in reward shaping (V7.1), not feature engineering.
- **Grouped by signal type**: Enables ablation testing (disable one group, measure impact).
- **Declarative architecture**: Each feature is defined once via a `FeatureDescriptor` — index, name, group, neutral value, valid range. No scattered parallel arrays. Single source of truth.

---

## Audit of Existing 42 Features

Before adding features, evaluate which of the existing 42 carry signal and which are candidates for removal.

### Likely High-Value (keep)

| Features | Count | Rationale |
|----------|-------|-----------|
| `f_price_change_{1,2,3,4}` | 4 | Short-term momentum. Most predictive lookbacks for batch auction frequency. |
| `f_log_return_{1,2,3,4}` | 4 | Same signal as price change but better for multiplicative models. Keep both — trees will use whichever splits better. |
| `f_rsi_8` | 1 | Mean-reversion signal. Well-established. |
| `f_macd_line`, `f_macd_histogram` | 2 | Trend direction and acceleration. Core momentum signals. |
| `f_bb_percent_b` | 1 | Normalized position within volatility bands. Good mean-reversion trigger. |
| `f_atr_8` | 1 | Volatility measure. Essential for normalizing other features. |
| `f_has_active_news`, `f_news_sentiment` | 2 | Event-driven signal. Direct catalyst for moves. |

### Possibly Redundant (validate empirically)

| Features | Count | Concern |
|----------|-------|---------|
| `f_price_change_{6,8,12,16,24,32,48,64}` | 8 | Longer lookbacks may be noise at batch-auction frequency. Keep if MI > 0.01. |
| `f_log_return_{6,8,...,64}` | 8 | Same concern. Highly correlated with corresponding price_change. May be redundant. |
| `f_sma_8`, `f_sma_16`, `f_ema_8`, `f_ema_16` | 4 | Raw indicator values are price-dependent. `f_trend_strength` (EMA gap / ATR) may be strictly better. |
| `f_bb_upper`, `f_bb_middle`, `f_bb_lower` | 3 | Raw Bollinger values are price-dependent. `f_bb_percent_b` already captures the normalized position. These 3 may be redundant. |
| `f_macd_signal` | 1 | Highly correlated with `f_macd_line`. Histogram = line - signal, so signal is derivable. |
| `f_mid_price` | 1 | Raw price level. Not a signal — AAPL at $150 vs $200 doesn't predict direction. Only useful as denominator. |
| `f_news_magnitude`, `f_news_ticks_remaining` | 2 | May not carry incremental signal over sentiment. Validate. |

### Recommended Validation Process

1. Record 50k ticks with all 42 features
2. Compute mutual information of each feature vs next-tick return sign
3. Compute pairwise Pearson correlation
4. Remove candidates: MI < 0.005 AND no unique information (covered by correlated feature)
5. Retrain V5 tree model with reduced set, compare accuracy

**Expected outcome**: Some base features will have low MI / high redundancy. However, **trimming is deferred to post-V6.2** to preserve V5 model index compatibility. Dead-weight features are kept as stable indices — trees ignore them. Trimming happens after SHAP analysis provides empirical evidence.

### Additional Feature Candidates (Round 2, if validation shows gaps)

These are not in the initial 13 but could be added if empirical analysis shows the initial set misses important signals:

| Feature | Formula | Signal | When to Add |
|---------|---------|--------|-------------|
| `f_return_autocorrelation` | `corr(returns[-8:], returns[-16:-8])` | Trending (+) vs mean-reverting (-) regime | If vol features alone don't capture regime |
| `f_momentum_persistence` | Count of consecutive same-sign returns | Trend durability/exhaustion | If trend_strength lacks predictive power |
| `f_vwap_deviation` | `(mid - vwap) / vwap` | Price vs volume-weighted average | Requires VWAP tracking infrastructure |
| `f_avg_trade_size` | `sum(trade_volumes) / n_trades` | Informed vs noise flow | If trade_intensity alone is insufficient |
| `f_cross_symbol_corr` | Rolling correlation between symbols | Market-wide risk regime | Only for multi-symbol configurations |
| `f_price_acceleration` | `price_change_1 - price_change_2` | Second derivative of price | If momentum features miss turning points |

**Process**: Start with the 13 new features. After V6.2 ensemble training, run SHAP analysis. If feature importance is concentrated in <5 features, the rest may be noise. Add Round 2 candidates to fill gaps, re-validate.

---

## New Centralized Market Features (13 new, indices 42-54)

Features are indexed **contiguously by group** to enable clean ablation testing.

### Microstructure Signals (liquidity & flow) — indices 42-44

| Index | Name | Formula | Signal | Why It Matters |
|-------|------|---------|--------|----------------|
| 42 | `f_spread_bps` | `(ask - bid) / mid * 10000` | Liquidity cost | Wide spread = illiquid, risky to trade. Tight = safe. Reflects market maker confidence. |
| 43 | `f_book_imbalance` | `(bid_vol - ask_vol) / (bid_vol + ask_vol)` | Residual order flow | Batch auction clears books each tick. Remaining orders reflect the *previous* tick's unmatched flow — what agents collectively submitted. Positive = net buying pressure last tick. Acts as crowd sentiment indicator. |
| 44 | `f_net_order_flow` | `(n_buyers - n_sellers) / (n_buyers + n_sellers)` | Agent count imbalance | Measures directional participation from last tick's executed trades. 10 buyers and 2 sellers = broad buying interest through few liquidity providers. Normalized to [-1, 1]. |

**Caveat on book_imbalance**: In batch auctions, book imbalance measures *residual* order flow, not persistent supply/demand. May be noise — evaluate empirically alongside `f_net_order_flow` in post-V6.2 SHAP analysis.

**Caveat on net_order_flow**: In batch auctions, every trade has equal buy and sell **volume** (no aggressor side). So `(buy_vol - sell_vol) / total = 0` always. The formula uses **unique agent counts** instead: `n_buyers = |{trade.buyer_id}|`, `n_sellers = |{trade.seller_id}|` from `ctx.recent_trades(symbol)`. Division by zero if no trades → NaN.

**Data sources**:
- `f_spread_bps`: `ctx.best_bid()`, `ctx.best_ask()`, `ctx.mid_price()`
- `f_book_imbalance`: `ctx.total_bid_volume()`, `ctx.total_ask_volume()`
- `f_net_order_flow`: `ctx.recent_trades(symbol)` → unique `buyer_id` and `seller_id` counts

### Volatility Regime (risk & opportunity sizing) — indices 45-47

| Index | Name | Formula | Signal | Why It Matters |
|-------|------|---------|--------|----------------|
| 45 | `f_realized_vol_8` | `std(log_returns[-8:])` | Short-term volatility | High vol = larger expected moves. Models should size positions inversely to vol. |
| 46 | `f_realized_vol_32` | `std(log_returns[-32:])` | Long-term vol baseline | Stable reference. Low vol for extended periods often precedes breakouts. |
| 47 | `f_vol_ratio` | `vol_8 / vol_32` | Regime change indicator | >1 = vol expanding (breakout likely), <1 = vol contracting (mean-reversion regime). |

**Data source**: Computed from sequential 1-period log returns over candle history. Requires candle history of 32+ ticks (available after warmup).

**Pure computation** (added to `types/src/features.rs`):
```rust
/// Compute realized volatility (standard deviation of sequential 1-period log returns).
///
/// IMPORTANT: Uses sequential returns ln(close[t] / close[t-1]) for consecutive candles,
/// NOT cumulative returns from `log_return_from_candles()` which computes
/// ln(close[-1] / close[-(i+1)]) — overlapping cumulative returns whose std dev
/// mechanically increases with horizon and is NOT realized volatility.
pub fn realized_volatility(candles: &[Candle], lookback: usize) -> f64 {
    if candles.len() < lookback + 1 { return f64::NAN; }
    let n = candles.len();
    let returns: Vec<f64> = (0..lookback)
        .map(|i| {
            let current = candles[n - 1 - i].close.to_float();
            let previous = candles[n - 2 - i].close.to_float();
            if current > 0.0 && previous > 0.0 {
                (current / previous).ln()
            } else {
                f64::NAN
            }
        })
        .filter(|r| r.is_finite())
        .collect();
    if returns.len() < 2 { return f64::NAN; }
    let mean = returns.iter().sum::<f64>() / returns.len() as f64;
    let variance = returns.iter().map(|r| (r - mean).powi(2)).sum::<f64>() / (returns.len() - 1) as f64;
    variance.sqrt()
}
```

### Fundamental Value (mean-reversion anchor) — indices 48-49

| Index | Name | Formula | Signal | Why It Matters |
|-------|------|---------|--------|----------------|
| 48 | `f_fair_value_dev` | `(mid - fair_value) / fair_value` | Mispricing magnitude | Deviation from Gordon Growth Model fair value. Large positive = overpriced, negative = underpriced. Mean-reversion signal. |
| 49 | `f_price_to_fair` | `mid / fair_value` | Valuation ratio | >1.0 overvalued, <1.0 undervalued. Simple, interpretable. Trees can split on this directly. |

**Data source**: `ctx.fair_value(symbol)` (V2.4 fundamentals system). Returns `None` if no fundamentals configured — impute with NaN → per-feature neutral value (0.0 for deviation, 1.0 for ratio).

### Momentum Quality (trend strength) — indices 50-51

| Index | Name | Formula | Signal | Why It Matters |
|-------|------|---------|--------|----------------|
| 50 | `f_trend_strength` | `abs(ema_8 - ema_16) / atr_8` | Normalized trend magnitude | Raw EMA gap is price-dependent. Dividing by ATR normalizes across price levels and volatility regimes. Values >2 indicate strong trends. |
| 51 | `f_rsi_divergence` | `rsi_8 - 50.0` | Directional conviction | RSI centered at 0. Range [-50, +50]. Avoids the overbought/oversold boundaries (30/70) which are regime-dependent. Trees learn their own optimal thresholds. |

**Data source**: `ctx.get_indicator(symbol, IndicatorType::Ema(8))`, `ctx.get_indicator(symbol, IndicatorType::Rsi(8))`, etc. — all pre-computed in V5 `IndicatorSnapshot`.

### Volume Dynamics & Cross-Feature — indices 52-54

| Index | Name | Formula | Signal | Why It Matters |
|-------|------|---------|--------|----------------|
| 52 | `f_volume_surge` | `latest_candle.volume / avg_volume_8` | Volume spike detection | Abnormal volume often precedes or confirms directional moves. Ratio normalizes across symbols. |
| 53 | `f_trade_intensity` | `n_recent_trades / 8.0` | Activity level | Trade frequency proxy. High intensity = market attention. Low = quiet, less predictable. |
| 54 | `f_sentiment_price_gap` | `symbol_sentiment * fair_value_dev` | Interaction term | Positive when news sentiment aligns with fundamental mispricing. Negative when they conflict. Captures "smart money" signal — news + value agreement is stronger than either alone. |

**`f_volume_surge` computation detail**: No pre-computed volume SMA exists in the indicator system. Compute inline from candle history. The average EXCLUDES the latest candle to avoid dampening the signal (a 10x spike should show as ~10x, not ~2.3x):
```rust
let candles = ctx.candles(symbol);
let n_prev = candles.len().saturating_sub(1).min(8);
let vol_avg = if n_prev > 0 {
    candles.iter().rev().skip(1).take(8).map(|c| c.volume.raw() as f64).sum::<f64>() / n_prev as f64
} else { 0.0 };
let latest_vol = ctx.last_candle(symbol).map(|c| c.volume.raw() as f64).unwrap_or(f64::NAN);
// NaN if no previous candles or zero average volume (early warmup)
if vol_avg > 0.0 { latest_vol / vol_avg } else { f64::NAN }
```

**`f_trade_intensity` window**: `ctx.recent_trades(symbol)` returns trades from the **previous tick** (updated in Phase 10, after the auction; StrategyContext is built in Phase 3, before the auction). The normalizer `TRADE_INTENSITY_BASELINE = 8.0` represents a baseline trade count per tick.

**`f_sentiment_price_gap` NaN handling**: This interaction term MUST be computed **before** the NaN imputation pass. If `f_fair_value_dev` is NaN (no fundamentals configured), the product must also be NaN — not `sentiment * 0.0` which masks the missing signal:
```rust
let sentiment = ctx.symbol_sentiment(symbol);
let fv_dev = buf[extended_idx::FAIR_VALUE_DEV]; // Still raw NaN at this point
buf[extended_idx::SENTIMENT_PRICE_GAP] = if fv_dev.is_nan() {
    f64::NAN  // Correctly marks as missing, imputed to neutral later
} else {
    sentiment * fv_dev
};
```

**Data sources**: Candle volume from `ctx.last_candle()`, trade count from `ctx.recent_trades()`, sentiment from `ctx.symbol_sentiment()`.

---

## Why No Per-Agent Portfolio Features

Per-agent features (position, cash, unrealized P&L) were considered and rejected:

- **Sunk cost fallacy**: Current position is sunk cost. The optimal action depends on where the market is going, not where the agent entered. Encoding position biases toward disposition effect (hold losers, sell winners).
- **Position limits already enforced**: `PositionValidator` rejects orders that exceed limits. The model doesn't need to "know" its position to avoid overextension — the system handles it.
- **Risk management belongs in rewards**: V7.1 reward shaping (drawdown penalty, volatility penalty) is the correct mechanism for position risk, not feature engineering.
- **Simplifies architecture**: All features are centralized and cacheable. EnsembleAgent uses cached features directly, same as TreeAgent. No two-tier feature model needed.

If V7 RL shows evidence that position-awareness improves performance, portfolio features can be added as an experiment. But they should not be assumed useful.

---

## Architecture: Declarative Feature Registry

V6.1 introduces a **declarative feature registry** that replaces scattered parallel arrays with a single source of truth per feature. This is the architectural foundation for V6.2 (SHAP metadata), V6.3 (canonical features), V6.4 (gym observation space), V6.5 (PyO3 schema export), and V7.2 (NN normalization ranges).

### Design Goals

1. **Single source of truth**: Each feature's index, name, group, neutral value, and valid range defined in one place
2. **Compile-time safety**: Index consistency verified exhaustively at compile time (not just the last index)
3. **Group-level modularity**: Feature groups are first-class concepts — extraction, ablation, and analysis all operate at group level
4. **SoC**: Declaration (what features exist) separated from computation (how they're extracted), imputation (how NaN is handled), and validation (range checking)

### FeatureGroup Enum (`crates/types/src/features.rs`)

```rust
/// Signal groups for feature ablation and modular extraction.
/// Contiguous index ranges enable clean group-level operations.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum FeatureGroup {
    Price,              // 0-24: mid_price, price_change_*, log_return_*
    TechnicalIndicator, // 25-37: SMA, EMA, RSI, MACD, BB, ATR
    News,               // 38-41: has_active_news, sentiment, magnitude, ticks_remaining
    Microstructure,     // 42-44: spread_bps, book_imbalance, net_order_flow
    Volatility,         // 45-47: realized_vol_8, realized_vol_32, vol_ratio
    Fundamental,        // 48-49: fair_value_dev, price_to_fair
    MomentumQuality,    // 50-51: trend_strength, rsi_divergence
    VolumeCross,        // 52-54: volume_surge, trade_intensity, sentiment_price_gap
}
```

First three groups (Price, TechnicalIndicator, News) cover existing V5 features 0-41. Last five cover V6.1 additions 42-54. Groups are contiguous by index for clean ablation.

### FeatureDescriptor Struct (`crates/types/src/features.rs`)

```rust
/// Complete description of a single feature.
/// Co-locates all metadata that was previously scattered across
/// idx constants, MARKET_FEATURE_NAMES, MINIMAL_FEATURE_NEUTRALS, and code comments.
#[derive(Debug, Clone, Copy)]
pub struct FeatureDescriptor {
    pub index: usize,            // positional index in feature vector
    pub name: &'static str,      // machine-readable name (Parquet, SHAP, PyO3)
    pub group: FeatureGroup,     // signal group for ablation
    pub neutral: f64,            // imputation value when NaN ("no signal")
    pub valid_range: (f64, f64), // expected [min, max] for validation & NN normalization
}
```

### FeatureRegistry (`crates/types/src/features.rs`)

Thin wrapper providing derived accessors over a static descriptor array:

```rust
pub struct FeatureRegistry {
    descriptors: &'static [FeatureDescriptor],
    names: &'static [&'static str],     // pre-computed for &[&str] return type
    neutrals: &'static [f64],           // pre-computed for &[f64] return type
}

impl FeatureRegistry {
    pub fn len(&self) -> usize;
    pub fn get(&self, index: usize) -> &FeatureDescriptor;
    pub fn descriptors(&self) -> &[FeatureDescriptor];
    pub fn names(&self) -> &[&str];
    pub fn neutrals(&self) -> &[f64];
    pub fn group_indices(&self, group: FeatureGroup) -> Vec<usize>;  // for ablation
    pub fn valid_ranges(&self) -> Vec<(f64, f64)>;                   // for V7.2 NN normalization
    pub fn validate(&self, features: &[f64]) -> Vec<usize>;          // out-of-range indices
}
```

**Why parallel name/neutral arrays alongside descriptors?** Rust's const system cannot produce `&'static [&'static str]` from `&'static [FeatureDescriptor]` at compile time. The parallel arrays are the runtime-efficient access path; compile-time assertions verify they match the descriptors. The descriptors remain the authoritative definition.

### Static Registries

```rust
pub static MINIMAL_REGISTRY: FeatureRegistry;  // 42 features, neutrals all -1.0 (V5 compat)
pub static FULL_REGISTRY: FeatureRegistry;      // 55 features, semantic neutrals
```

### FeatureExtractor Trait Extension (`crates/agents/src/tier1/ml/mod.rs`)

Add `registry()` method for downstream consumers:

```rust
pub trait FeatureExtractor: Send + Sync {
    fn n_features(&self) -> usize;
    fn extract_market(&self, symbol: &Symbol, ctx: &StrategyContext<'_>) -> FeatureVec;
    fn feature_names(&self) -> &[&str];
    fn neutral_values(&self) -> &[f64];
    fn registry(&self) -> &'static FeatureRegistry;  // NEW: access to full metadata
}
```

`MinimalFeatures::registry()` returns `&MINIMAL_REGISTRY`. `FullFeatures::registry()` returns `&FULL_REGISTRY`.

### Compile-Time Assertions (stronger than current)

```rust
const _: () = {
    // Every descriptor index equals its array position (no gaps, duplicates, or mismatches)
    assert!(FULL_DESCRIPTORS[0].index == 0);
    assert!(FULL_DESCRIPTORS[1].index == 1);
    // ... all 55

    // Prefix consistency: first 42 of FULL match MINIMAL indices
    assert!(FULL_DESCRIPTORS[0].index == MINIMAL_DESCRIPTORS[0].index);
    // ... all 42

    // Length checks
    assert!(MINIMAL_DESCRIPTORS.len() == N_MARKET_FEATURES);
    assert!(FULL_DESCRIPTORS.len() == N_FULL_FEATURES);
    assert!(FULL_FEATURE_NAMES.len() == N_FULL_FEATURES);
    assert!(FULL_FEATURE_NEUTRALS.len() == N_FULL_FEATURES);
};
```

This is strictly stronger than the current assertion (which only checks `NEWS_TICKS_REMAINING == N_MARKET_FEATURES - 1`). Catches any index mismatch at compile time.

---

## Architecture: Group Extraction Functions

Feature extraction is organized by group using free functions (not trait objects). Each function writes into a pre-allocated `&mut [f64]` buffer at the correct indices.

### Why free functions (not trait objects)

All 8 groups are known at compile time. No group carries configuration state. Free functions are simpler, inlineable, and equally modular. Ablation is handled via `HashSet<FeatureGroup>` check before calling each function.

### Group Extractors (`crates/agents/src/tier1/ml/group_extractors.rs`)

```rust
pub fn extract_price(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_technical(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_news(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_microstructure(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_volatility(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_fundamental(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_momentum_quality(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
pub fn extract_volume_cross(symbol: &Symbol, ctx: &StrategyContext<'_>, buf: &mut [f64]);
```

The first three are refactored out of the existing `extract_features_raw()`. The latter five are new V6.1 code.

**Extraction order matters**: `extract_volume_cross` reads `buf[extended_idx::FAIR_VALUE_DEV]` written by `extract_fundamental`. Call order enforced in `FullFeatures::extract_market()`.

### FullFeatures Extractor (`crates/agents/src/tier1/ml/full_features.rs`)

```rust
pub struct FullFeatures {
    disabled_groups: HashSet<FeatureGroup>,  // for ablation testing
}

impl FeatureExtractor for FullFeatures {
    fn n_features(&self) -> usize { N_FULL_FEATURES }

    fn extract_market(&self, symbol: &Symbol, ctx: &StrategyContext<'_>) -> FeatureVec {
        let mut buf = smallvec::smallvec![f64::NAN; N_FULL_FEATURES];

        // Call each group function unless disabled. Disabled groups stay NaN.
        if !self.disabled_groups.contains(&FeatureGroup::Price) {
            extract_price(symbol, ctx, &mut buf);
        }
        if !self.disabled_groups.contains(&FeatureGroup::TechnicalIndicator) {
            extract_technical(symbol, ctx, &mut buf);
        }
        if !self.disabled_groups.contains(&FeatureGroup::News) {
            extract_news(symbol, ctx, &mut buf);
        }
        if !self.disabled_groups.contains(&FeatureGroup::Microstructure) {
            extract_microstructure(symbol, ctx, &mut buf);
        }
        if !self.disabled_groups.contains(&FeatureGroup::Volatility) {
            extract_volatility(symbol, ctx, &mut buf);
        }
        if !self.disabled_groups.contains(&FeatureGroup::Fundamental) {
            extract_fundamental(symbol, ctx, &mut buf);
        }
        if !self.disabled_groups.contains(&FeatureGroup::MomentumQuality) {
            extract_momentum_quality(symbol, ctx, &mut buf);
        }
        // VolumeCross MUST come after Fundamental (reads fair_value_dev from buf)
        if !self.disabled_groups.contains(&FeatureGroup::VolumeCross) {
            extract_volume_cross(symbol, ctx, &mut buf);
        }

        buf  // NaN preserved — imputation is a separate pipeline step
    }

    fn feature_names(&self) -> &[&str] { FULL_FEATURE_NAMES }
    fn neutral_values(&self) -> &[f64] { &FULL_FEATURE_NEUTRALS }
    fn registry(&self) -> &'static FeatureRegistry { &FULL_REGISTRY }
}
```

### Per-Feature Neutral Values for NaN Imputation

`FullFeatures` uses **per-feature neutral values** instead of uniform -1.0. `MinimalFeatures` keeps -1.0 for V5 backward compat. Imputation is applied by `impute_features()` in the runner, after extraction.

```rust
pub const FULL_FEATURE_NEUTRALS: [f64; N_FULL_FEATURES] = [
    // Price (25): 0.0 = no change/no price info
    0.0,  // f_mid_price
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  // price_change_*
    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  // log_return_*

    // Technical indicators (13)
    0.0, 0.0,       // SMA 8/16 (raw price, 0 = no info)
    0.0, 0.0,       // EMA 8/16
    50.0,            // RSI 8 (neutral midpoint)
    0.0, 0.0, 0.0,  // MACD line/signal/histogram (no trend)
    0.0, 0.0, 0.0,  // BB upper/middle/lower (raw price)
    0.5,             // BB %B (middle of band)
    0.0,             // ATR 8 (no volatility info)

    // News (4): 0.0 = no news
    0.0, 0.0, 0.0, 0.0,

    // Microstructure (3)
    0.0,  // spread_bps (tight spread assumed)
    0.0,  // book_imbalance (balanced)
    0.0,  // net_order_flow (balanced)

    // Volatility (3)
    0.0,  // realized_vol_8 (zero vol during warmup)
    0.0,  // realized_vol_32
    1.0,  // vol_ratio (no regime change)

    // Fundamental (2)
    0.0,  // fair_value_dev (at fair value)
    1.0,  // price_to_fair (at fair value)

    // Momentum quality (2)
    0.0,  // trend_strength (no trend)
    0.0,  // rsi_divergence (neutral RSI)

    // Volume/cross (3)
    1.0,  // volume_surge (normal volume)
    0.0,  // trade_intensity (no trades)
    0.0,  // sentiment_price_gap (no signal)
];
```

**Why per-feature neutrals instead of uniform -1.0**:
- **Trees**: Split thresholds are learned from data. Whether missing = -1.0 or 0.0, performance is identical.
- **Neural nets (V7.2)**: -1.0 falls within the normal range of many features (returns, sentiment). NN can't distinguish "missing" from "value is -1.0". Per-feature neutrals are semantically correct "no signal."
- **Training parity**: Export `FULL_FEATURE_NEUTRALS` to Python as the imputation map.

### How the Registry Serves Downstream Consumers

**V6.2 SHAP analysis**:
```rust
let registry = extractor.registry();
for group in FeatureGroup::ALL {
    let indices = registry.group_indices(group);
    let group_shap: f64 = indices.iter().map(|&i| shap_values[i].abs()).sum();
    println!("{:?}: total |SHAP| = {:.4}", group, group_shap);
}
```

**V6.4 gym observation space**:
```rust
let registry = extractor.registry();
let obs_space = ObservationSpace {
    shape: vec![registry.len()],
    low: registry.descriptors().iter().map(|d| d.valid_range.0).collect(),
    high: registry.descriptors().iter().map(|d| d.valid_range.1).collect(),
};
```

**V6.5 PyO3 schema export**:
```rust
#[pyfunction]
fn feature_schema() -> Vec<(usize, String, String, f64, (f64, f64))> {
    FULL_REGISTRY.descriptors().iter().map(|d| {
        (d.index, d.name.to_string(), format!("{:?}", d.group), d.neutral, d.valid_range)
    }).collect()
}
```

**V7.2 NN normalization**:
```rust
let ranges = extractor.registry().valid_ranges();
// Features with finite ranges → min-max normalization
// Features with infinite ranges → z-score from training data
```

**Ablation testing (post-V6.2)**:
```rust
for group in FeatureGroup::ALL {
    let mut extractor = FullFeatures::new();
    extractor.disable_group(group);
    let accuracy = train_and_evaluate(extractor);
    println!("Without {:?}: accuracy={:.4}", group, accuracy);
}
```

### Recording Update

**Prerequisite**: Pre-V6 refactor section F complete — features are pre-extracted in the runner (Phase 3) and passed to `RecordingHook` via `EnrichedData.features`. Training-serving parity guaranteed by construction.

Update `--headless-record` to accept a `FeatureExtractor`:
- CLI flag: `--full-features` (default: MinimalFeatures for backward compatibility)
- When `--full-features`: uses `FullFeatures` extractor, Parquet has 55 columns
- Existing recordings with 42 columns remain valid

---

## Index Constants (`crates/types/src/features.rs`)

```rust
pub const N_FULL_FEATURES: usize = 55;

pub mod extended_idx {
    // Microstructure (42-44)
    pub const SPREAD_BPS: usize = 42;
    pub const BOOK_IMBALANCE: usize = 43;
    pub const NET_ORDER_FLOW: usize = 44;

    // Volatility (45-47)
    pub const REALIZED_VOL_8: usize = 45;
    pub const REALIZED_VOL_32: usize = 46;
    pub const VOL_RATIO: usize = 47;

    // Fundamental (48-49)
    pub const FAIR_VALUE_DEV: usize = 48;
    pub const PRICE_TO_FAIR: usize = 49;

    // Momentum quality (50-51)
    pub const TREND_STRENGTH: usize = 50;
    pub const RSI_DIVERGENCE: usize = 51;

    // Volume/cross (52-54)
    pub const VOLUME_SURGE: usize = 52;
    pub const TRADE_INTENSITY: usize = 53;
    pub const SENTIMENT_PRICE_GAP: usize = 54;
}
```

Note: Indices are now **contiguous by group** (microstructure 42-44, volatility 45-47, etc.) rather than the original ordering where `net_order_flow` was at 54. This enables clean group-level ablation and is consistent with the `FeatureGroup` enum ranges.

---

## Files Summary

| File | Action |
|------|--------|
| `crates/types/src/features.rs` | MODIFY: add `FeatureDescriptor`, `FeatureGroup`, `FeatureRegistry`, `FULL_REGISTRY`, `MINIMAL_REGISTRY`, `extended_idx`, pure functions, compile-time assertions |
| `crates/agents/src/tier1/ml/mod.rs` | MODIFY: add `registry()` to `FeatureExtractor` trait, export new types |
| `crates/agents/src/tier1/ml/feature_extractor.rs` | MODIFY: update `MinimalFeatures` to implement `registry()` |
| `crates/agents/src/tier1/ml/group_extractors.rs` | CREATE: 8 group extraction functions (3 refactored from `extract_features_raw()`, 5 new) |
| `crates/agents/src/tier1/ml/full_features.rs` | CREATE: `FullFeatures` struct with ablation support, implementing `FeatureExtractor` |
| `crates/agents/src/lib.rs` | MODIFY: export `FullFeatures`, `FeatureGroup` |
| `src/main.rs` | MODIFY: add `--full-features` CLI flag |

---

## Feature Validation Plan (post-implementation, pre-V6.2)

1. **Record 50k ticks** with `--headless-record --full-features --ticks 50000`
2. **NaN rate report**: For each feature, compute fraction of ticks where the raw value was NaN (before imputation). Features with >80% NaN carry no signal — they are effectively constants (the neutral value). Pay special attention to `spread_bps` and `book_imbalance` which may be frequently NaN in batch auction markets.
3. **Correlation matrix**: In Python, compute pairwise Pearson correlation. Flag features with |r| > 0.95 as redundant.
3. **Mutual information**: Compute MI between each feature and next-tick return sign. Features with MI < 0.01 are likely noise.
4. **Compare `f_book_imbalance` vs `f_net_order_flow`**: Compute MI for both. If correlated (|r| > 0.8), keep whichever has higher MI.
5. **Feature importance (post-V6.2)**: After ensemble training, run SHAP analysis. Features with near-zero SHAP values across all models are candidates for removal.
6. **Ablation (post-V6.2)**: Use `FullFeatures::disable_group()` to retrain ensemble with one feature group disabled at a time. Measure accuracy drop to quantify each group's contribution.
7. **Trimming (post-V6.2)**: Remove features identified in steps 2-6. Update `N_FULL_FEATURES`, re-index, retrain.

---

## Verification

1. `cargo test -p types` — compile-time assertions pass, pure function unit tests pass
2. `cargo test -p agents` — group extractor unit tests, equivalence test (V5 group functions == `extract_features_raw()`)
3. `cargo build` — full compilation with new trait method
4. `cargo run -- --headless-record --full-features --ticks 500` — produces Parquet with 55 columns
5. Python: `pd.read_parquet("data/training_000.parquet")` — all 55 columns present, no NaN in imputed columns
6. **Imputation check**: Verify NaN values are imputed to per-feature neutrals (not uniform -1.0). Check: `f_vol_ratio` missing → 1.0, `f_rsi_divergence` missing → 0.0, `f_bb_percent_b` missing → 0.5
7. Backward compat: `cargo run -- --headless-record --ticks 500` (without `--full-features`) — still produces 42-column Parquet with -1.0 imputation
8. Feature ranges: spot-check that spread_bps in [0, 1000], book_imbalance in [-1, 1], net_order_flow in [-1, 1], vol in [0, 1], etc.
9. **Realized vol sanity**: Verify `realized_vol_8` < `realized_vol_32` is NOT always true (it shouldn't be — vol can expand or contract)
10. **Recording path parity**: Compare inference features (from ML cache) with recorded features for same tick — they should be identical (section F validation)
11. **Feature audit**: Run MI analysis and correlation check on 50k tick recording.
