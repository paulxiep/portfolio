# V5.3: Feature Recording Mode

## Overview

Add `--headless-record` mode to capture comprehensive per-tick data for ML training. The system records features, agent actions, and outcomes to Parquet files for Python consumption.

---

## CLI Interface

```bash
# Basic usage
cargo run --release -- --headless-record --record-output data/training.parquet

# With warm-up period (skip first N ticks)
cargo run --release -- --headless-record --record-output data/training.parquet --record-warmup 100

# Record every N ticks (for smaller datasets)
cargo run --release -- --headless-record --record-output data/training.parquet --record-interval 5

# Full example
cargo run --release -- --headless-record \
    --ticks 100000 \
    --record-output data/training.parquet \
    --record-warmup 500 \
    --record-interval 1
```

### New CLI Flags

| Flag | Type | Default | Description |
|------|------|---------|-------------|
| `--headless-record` | bool | false | Enable recording mode (implies `--headless`) |
| `--record-output` | String | `data/training.parquet` | Output file path |
| `--record-warmup` | u64 | 100 | Skip first N ticks before recording |
| `--record-interval` | u64 | 1 | Record every N ticks (1 = every tick) |

---

## Comprehensive Feature Set

Record everything potentially useful. Features can be pruned during training if found useless.

### 1. Price Features (per symbol)

| Feature | Type | Description |
|---------|------|-------------|
| `mid_price` | f64 | Current mid price |
| `spread` | f64 | `best_ask - best_bid` |
| `spread_bps` | f64 | Spread in basis points: `spread / mid_price * 10000` |
| `price_change_1` | f64 | Price change from 1 tick ago (%) |
| `price_change_5` | f64 | Price change from 5 ticks ago (%) |
| `price_change_20` | f64 | Price change from 20 ticks ago (%) |
| `price_change_100` | f64 | Price change from 100 ticks ago (%) |
| `log_return_1` | f64 | Log return: `ln(price_t / price_{t-1})` |
| `log_return_5` | f64 | Log return over 5 ticks |
| `log_return_20` | f64 | Log return over 20 ticks |

### 2. Technical Indicators (per symbol)

| Feature | Type | Description |
|---------|------|-------------|
| `sma_10` | f64 | Simple Moving Average (10 periods) |
| `sma_20` | f64 | Simple Moving Average (20 periods) |
| `sma_50` | f64 | Simple Moving Average (50 periods) |
| `ema_12` | f64 | Exponential Moving Average (12 periods) |
| `ema_26` | f64 | Exponential Moving Average (26 periods) |
| `rsi_14` | f64 | Relative Strength Index (14 periods) |
| `macd_line` | f64 | MACD line |
| `macd_signal` | f64 | MACD signal line |
| `macd_histogram` | f64 | MACD histogram |
| `bb_upper` | f64 | Bollinger upper band |
| `bb_middle` | f64 | Bollinger middle band (SMA 20) |
| `bb_lower` | f64 | Bollinger lower band |
| `bb_percent_b` | f64 | Bollinger %B: position within bands |
| `atr_14` | f64 | Average True Range (14 periods) |

### 4. Fundamental Features (per symbol)

| Feature | Type | Description |
|---------|------|-------------|
| `fair_value` | f64 | Gordon Growth Model fair value |
| `price_to_fair_value` | f64 | `mid_price / fair_value` |
| `fair_value_deviation` | f64 | `(mid_price - fair_value) / fair_value` (%) |

### 5. News/Sentiment Features (per symbol)

| Feature | Type | Description |
|---------|------|-------------|
| `has_active_news` | f64 | 1.0 if news event active, 0.0 otherwise |
| `news_sentiment` | f64 | Sentiment of active news (-1.0 to 1.0), 0.0 if none |
| `news_magnitude` | f64 | Magnitude of active news (0.0 to 1.0), 0.0 if none |
| `news_ticks_remaining` | f64 | Ticks until news expires, 0.0 if none |

### 6. Agent State Features (per agent)

| Feature | Type | Description |
|---------|------|-------------|
| `position` | f64 | Current position in symbol (shares) |
| `position_normalized` | f64 | Position / position_limit |
| `cash` | f64 | Current cash balance |
| `cash_normalized` | f64 | Cash / initial_cash |
| `total_pnl` | f64 | Total P&L (realized + unrealized) |
| `pnl_normalized` | f64 | Total P&L / initial_cash (%) |

### 7. Risk Features (per agent)

| Feature | Type | Description |
|---------|------|-------------|
| `equity` | f64 | Current equity value |
| `max_drawdown` | f64 | Maximum drawdown (0.0 to 1.0) |
| `sharpe` | f64 | Sharpe ratio (if available) |
| `volatility` | f64 | Annualized volatility (if available) |

### 8. Market Microstructure Features (global)

| Feature | Type | Description |
|---------|------|-------------|
| `tick` | u64 | Current tick number |
| `total_trades_this_tick` | u64 | Number of trades executed this tick |
| `total_volume_this_tick` | f64 | Total volume traded this tick |

### 9. Cross-Symbol Features (if multi-symbol)

| Feature | Type | Description |
|---------|------|-------------|
| `correlation_to_market` | f64 | Rolling correlation to market index |
| `relative_strength` | f64 | Symbol return vs market return |

---

## Output Schema

### Parquet Schema

```
Schema: FeatureRecord
├── tick: UInt64 (partition key candidate)
├── agent_id: UInt64
├── agent_name: String
├── symbol: String
│
├── # Pre-tick features (state before action)
├── f_mid_price: Float64
├── f_spread: Float64
├── f_spread_bps: Float64
├── f_price_change_1: Float64
├── f_price_change_5: Float64
├── f_price_change_20: Float64
├── f_price_change_100: Float64
├── f_log_return_1: Float64
├── f_log_return_5: Float64
├── f_log_return_20: Float64
├── f_sma_10: Float64
├── f_sma_20: Float64
├── f_sma_50: Float64
├── f_ema_12: Float64
├── f_ema_26: Float64
├── f_rsi_14: Float64
├── f_macd_line: Float64
├── f_macd_signal: Float64
├── f_macd_histogram: Float64
├── f_bb_upper: Float64
├── f_bb_middle: Float64
├── f_bb_lower: Float64
├── f_bb_percent_b: Float64
├── f_atr_14: Float64
├── f_fair_value: Float64
├── f_price_to_fair_value: Float64
├── f_fair_value_deviation: Float64
├── f_has_active_news: Float64
├── f_news_sentiment: Float64
├── f_news_magnitude: Float64
├── f_news_ticks_remaining: Float64
├── f_position: Float64
├── f_position_normalized: Float64
├── f_cash: Float64
├── f_cash_normalized: Float64
├── f_total_pnl: Float64
├── f_pnl_normalized: Float64
├── f_equity: Float64
├── f_max_drawdown: Float64
├── f_sharpe: Float64
├── f_volatility: Float64
│
├── # Action taken
├── action: Int8  # -1 = sell, 0 = hold, 1 = buy
├── action_quantity: Float64  # Shares attempted
├── action_price: Float64  # Limit price (if applicable)
│
├── # Outcome (computed from fills)
├── fill_quantity: Float64  # Actual shares filled
├── fill_price: Float64  # Average fill price
├── reward: Float64  # P&L change this tick
├── reward_normalized: Float64  # P&L change / initial_cash
│
├── # Next-tick features (for temporal difference learning)
├── next_mid_price: Float64
├── next_position: Float64
├── next_pnl: Float64
```

### Feature Naming Convention

- `f_` prefix for pre-tick features
- `next_` prefix for post-tick features
- No prefix for actions/outcomes

---

## Architecture

Aligned with vertical plan V5:

```
crates/
├── agents/src/tier1/ml/          # V5.3-V5.5: ML agent infrastructure
│   ├── mod.rs                    # pub use, MlModel trait
│   ├── features.rs               # FeatureExtractor trait, FeatureContext
│   ├── comprehensive_features.rs # ComprehensiveFeatures impl (V5.3)
│   ├── decision_tree.rs          # DecisionTree + JSON loader (V5.5)
│   └── tree_agent.rs             # TreeAgent<F, M> (V5.5)
│
├── storage/src/                  # Recording infrastructure (V5.3)
│   ├── recording_hook.rs         # RecordingHook impl
│   ├── parquet_writer.rs         # Buffered Parquet writer
│   └── price_history.rs          # Rolling price tracking
│
└── scripts/                      # V5.4: Python training scripts
    └── export_rf.py              # Train RF, export to JSON
```

**Rationale:**
- `FeatureExtractor` trait lives in `agents/` because ML agents use it for inference (V5.5)
- Recording infrastructure lives in `storage/` alongside existing `StorageHook`
- Same `FeatureExtractor` used for both recording (V5.3) and inference (V5.5)

### Key Traits (in `crates/agents/src/tier1/ml/`)

```rust
/// Context for feature extraction (subset of simulation state)
pub struct FeatureContext<'a> {
    pub tick: Tick,
    pub symbol: &'a Symbol,
    pub market: &'a MarketSnapshot,
    pub enriched: Option<&'a EnrichedData>,
    pub agent_summary: &'a AgentSummary,
    pub risk_snapshot: Option<&'a AgentRiskSnapshot>,
    pub price_history: &'a PriceHistory,  // For rolling calculations
}

/// Trait for feature extraction strategies
/// Used by both RecordingHook (V5.3) and TreeAgent (V5.5)
pub trait FeatureExtractor: Send + Sync {
    /// Return ordered list of feature names (for schema)
    fn feature_names(&self) -> &[&'static str];

    /// Extract features as f64 vector
    fn extract(&self, ctx: &FeatureContext) -> Vec<f64>;
}

/// Comprehensive feature extractor (~40 features)
pub struct ComprehensiveFeatures {
    lookback_periods: Vec<usize>,  // [1, 5, 20, 100]
}

impl FeatureExtractor for ComprehensiveFeatures {
    // ... implementation
}
```

### MlModel Trait (for V5.5, defined now for forward compatibility)

```rust
/// Trait for ML model inference
/// Implemented by DecisionTree (V5.5), LinearModel (V6), etc.
pub trait MlModel: Send + Sync {
    /// Predict action score from features
    fn predict(&self, features: &[f64]) -> f64;
}
```

### RecordingHook Flow

```
RecordingHook
├── on_tick_start(ctx)
│   └── Capture pre-tick features for each agent
│   └── Store in pending_records HashMap<AgentId, PartialRecord>
│
├── on_orders_collected(orders, ctx)
│   └── For each order, update pending_records[agent_id].action
│
├── on_trades(trades, ctx)
│   └── For each trade, accumulate fills in pending_records
│
├── on_tick_end(stats, ctx)
│   └── Compute rewards (P&L delta)
│   └── Capture next_* features
│   └── If tick >= warmup && (tick - warmup) % interval == 0:
│   │   └── Flush pending_records to ParquetWriter buffer
│   └── Clear pending_records
│
└── on_simulation_end(final_stats)
    └── Final flush to Parquet file
```

### Price History Tracking

```rust
/// Rolling price history for computing returns
pub struct PriceHistory {
    /// Symbol -> VecDeque of (tick, mid_price)
    history: HashMap<Symbol, VecDeque<(Tick, Price)>>,
    max_lookback: usize,  // 100 ticks
}

impl PriceHistory {
    pub fn record(&mut self, tick: Tick, symbol: &Symbol, price: Price);
    pub fn price_at(&self, symbol: &Symbol, ticks_ago: usize) -> Option<Price>;
    pub fn price_change(&self, symbol: &Symbol, ticks_ago: usize) -> Option<f64>;
    pub fn log_return(&self, symbol: &Symbol, ticks_ago: usize) -> Option<f64>;
}
```

---

## Implementation Phases

### Phase 1: Infrastructure (~0.5 day)
- [ ] Add `parquet`, `arrow` to `crates/storage/Cargo.toml`
- [ ] Add CLI flags to main.rs Args struct
- [ ] Create `crates/storage/src/price_history.rs`

### Phase 2: Feature Extraction (~1 day)
- [ ] Create `crates/agents/src/tier1/ml/` directory
- [ ] Define `FeatureContext` struct in `features.rs`
- [ ] Define `FeatureExtractor` trait in `features.rs`
- [ ] Define `MlModel` trait in `mod.rs` (stub for V5.5)
- [ ] Implement `ComprehensiveFeatures` in `comprehensive_features.rs`
- [ ] Unit tests for feature calculations

### Phase 3: Recording Hook (~0.5 day)
- [ ] Implement `ParquetWriter` in `crates/storage/src/parquet_writer.rs`
- [ ] Implement `RecordingHook` in `crates/storage/src/recording_hook.rs`
- [ ] Handle warmup period
- [ ] Handle record interval

### Phase 4: Integration (~0.5 day)
- [ ] Wire up in `run_headless()` when `--headless-record`
- [ ] Add to server mode as well (optional)
- [ ] End-to-end test

### Phase 5: Validation (~0.5 day)
- [ ] Run simulation, produce Parquet
- [ ] Load in Python, verify schema
- [ ] Check data quality (no NaNs where unexpected, reasonable ranges)

---

## Dependencies

**Add to `crates/storage/Cargo.toml`:**

```toml
[dependencies]
parquet = "54"  # Apache Arrow Parquet
arrow = "54"    # For schema definition
# existing deps: parking_lot, rusqlite, simulation, types
```

**Add to `crates/agents/Cargo.toml`:**

```toml
[dependencies]
# existing deps already sufficient for FeatureExtractor
# simulation (for HookContext types)
# types, quant
```

---

## Data Volume Estimates

| Scenario | Ticks | Agents | Rows | Size (est) |
|----------|-------|--------|------|------------|
| Quick test | 10,000 | 50 | 500K | ~50 MB |
| Standard | 100,000 | 100 | 10M | ~1 GB |
| Large | 1,000,000 | 100 | 100M | ~10 GB |

With `--record-interval 10`, reduce by 10x.

---

## Verification Checklist

After implementation, verify:

1. **Schema correctness**: Python can read Parquet, column names match
2. **No data before warmup**: First row tick >= warmup value
3. **Interval respected**: If interval=5, rows are at ticks 100, 105, 110...
4. **Feature ranges**: RSI in [0,100], spreads positive, etc.
5. **Action encoding**: -1/0/1 correctly assigned
6. **Reward calculation**: P&L delta matches expected from fills
7. **next_* features**: Match next row's f_* features (temporal consistency)

---

## Python Consumption Example

```python
import polars as pl

# Load training data
df = pl.read_parquet("data/training.parquet")

# Filter to specific agent type
df_mm = df.filter(pl.col("agent_name").str.contains("MarketMaker"))

# Select features for training
feature_cols = [c for c in df.columns if c.startswith("f_")]
X = df.select(feature_cols).to_numpy()
y = df["action"].to_numpy()

# Train Random Forest
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100, max_depth=10)
rf.fit(X, y)

# Feature importance
for name, importance in sorted(zip(feature_cols, rf.feature_importances_),
                                key=lambda x: -x[1])[:10]:
    print(f"{name}: {importance:.4f}")
```
