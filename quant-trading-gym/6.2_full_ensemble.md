# V6.2: Full Ensemble

## Overview

Add `LinearPredictor` (unified logistic regression + linear SVC), `GaussianNBPredictor`, and `EnsembleModel` -- all implementing `MlModel`. The ensemble composes any mix of model types via weighted probability averaging. Register it in `ModelRegistry`; predictions land in `MlPredictionCache`; standard `MlAgent` reads them. No new Agent impl needed.

The ensemble's sim performance becomes the baseline that V7.1 RL must beat.

**Requires**: V6.1 complete (`FullFeatures` extractor, 55 features in ML cache)

---

## Phase 0: Structural Refactors (DONE)

Three structural cleanups completed before adding new model types. These reduce the per-model-type integration cost from ~6 file changes to 1 match arm.

### R1. De-genericize TreeAgent -> MlAgent (DONE)

**Problem**: `TreeAgent<M: MlModel>` was vestigial -- since V5.6, `on_tick()` reads predictions from cache via `ctx.get_ml_prediction(model_name, symbol)`. The `model` field was used only for `.name()`. The generic `M` and per-agent model clone were dead weight.

**Fix**: Non-generic `MlAgent` that holds only a model name string:

```rust
// crates/agents/src/tier1/ml/ml_agent.rs
pub struct MlAgent {
    id: AgentId,
    config: MlAgentConfig,     // renamed from TreeAgentConfig
    state: AgentState,
    model_name: String,         // replaces model: M + PhantomData
}

impl MlAgent {
    pub fn new(id: AgentId, model_name: String, config: MlAgentConfig) -> Self { ... }
}
```

`on_tick()` body unchanged -- reads from cache, applies random jitter decorrelation, compares to thresholds. The 6 type aliases (`DecisionTreeAgent`, `RandomForestAgent`, etc.) are eliminated.

**Files changed**: `tree_agent.rs` -> `ml_agent.rs`, `ml/mod.rs`, `tier1/mod.rs`, `lib.rs`, `ml_agents.rs`

### R2. Collapse MlModels + SimConfig (DONE)

**Problem**: `MlModels` had per-type Vec fields (`decision_trees`, `random_forests`, `gradient_boosteds`). Adding V6.2 model types would require new fields, new `has_models()` branches, new registration loops, new spawn calls, new SimConfig count fields, new builder methods -- 6+ changes per type.

**Fix**: Unified `Vec<(String, Arc<dyn MlModel>)>` with type tag:

```rust
// crates/simulation/src/agent_factory/ml_agents.rs
pub struct MlModels {
    models: Vec<(String, Arc<dyn MlModel>)>,  // (model_type, model)
}

impl MlModels {
    pub fn push(&mut self, model_type: &str, model: impl MlModel + 'static) { ... }
    pub fn of_type(&self, model_type: &str) -> Vec<&Arc<dyn MlModel>> { ... }
}
```

SimConfig replaced 3 per-type count fields with a HashMap:

```rust
// crates/simulation/src/sim_config.rs
pub ml_agent_counts: HashMap<String, usize>,

// Default:
ml_agent_counts: HashMap::from([
    ("decision_tree".into(), 400),
    ("random_forest".into(), 100),
    ("gradient_boosted".into(), 200),
]),
```

Spawning iterates the HashMap keys, groups loaded models by type, spawns agents per type count. Adding a new model type costs exactly 1 match arm in `load_ml_models()` + 1 HashMap entry in default config.

**Files changed**: `ml_agents.rs`, `sim_config.rs`, `main.rs`

### R6. Zero-alloc softmax (DONE)

**Problem**: `softmax()` heap-allocated `Vec<f64>` for 3 values on every call.

**Fix**: Inline `[f64; 3]` computation:

```rust
pub(crate) fn softmax(scores: &[f64]) -> ClassProbabilities {
    let max_score = scores[0].max(scores[1]).max(scores[2]);
    let e = [
        (scores[0] - max_score).exp(),
        (scores[1] - max_score).exp(),
        (scores[2] - max_score).exp(),
    ];
    let sum = e[0] + e[1] + e[2];
    if sum > 0.0 && sum.is_finite() {
        [e[0] / sum, e[1] / sum, e[2] / sum]
    } else {
        [0.0, 1.0, 0.0]
    }
}
```

**File changed**: `crates/agents/src/tier1/ml/mod.rs`

---

## Design Decisions

### 1. Unified LinearPredictor (DRY)

Both logistic regression and linear SVC compute `softmax(W*x + b)`. The difference is training loss (logistic vs hinge), not inference. One `LinearPredictor` struct handles both via serde aliasing:

- JSON with `"coefficients"` / `"intercepts"` (sklearn LogisticRegression) -> maps to `weights` / `biases` fields
- JSON with `"weights"` / `"biases"` (sklearn LinearSVC) -> maps directly

The `model_type` field (`"linear_model"` or `"svm_linear"`) is preserved in JSON for the model loader dispatch and name prefixing in logs, but produces the same Rust struct.

**Why not separate structs**: An RBF kernel SVM would require a fundamentally different computation (kernel evaluation against support vectors), not a tweak to the linear path. If needed, that becomes `RbfSvmPredictor` -- a genuinely different struct. No premature abstraction.

### 2. EnsembleModel Is MlModel (Not a New Agent)

**Key architectural decision**: The ensemble is a MODEL, not an AGENT.

`EnsembleModel` implements `MlModel` and wraps `Vec<Arc<dyn MlModel>>`. Any model type (trees, linear, SVM, Naive Bayes, future neural nets) can participate. Its `predict()` runs sub-models internally and returns weighted-average probabilities.

Registered in `ModelRegistry`, predictions land in `MlPredictionCache` under the ensemble's name. The standard `MlAgent` reads them via `ctx.get_ml_prediction("Ensemble_v6", symbol)`. Threshold logic, position limits, order generation -- all reused from `MlAgent`.

**Data flow (unchanged)**:
```
Runner -> extract features -> cache -> ModelRegistry.predict_from_cache()
  (EnsembleModel.predict() calls sub-models internally)
  -> cache.insert_prediction("Ensemble_v6", symbol, probs)
  -> MlAgent reads from cache -> threshold logic -> orders
```

**Why not EnsembleAgent**:
- Duplicating ~60 lines of threshold/order logic from `MlAgent::on_tick()` violates SoC
- Bypassing the centralized prediction cache breaks the "extract once, predict once, cache everywhere" pattern
- Other consumers (recording hooks, gym observation, SHAP) cannot access ensemble predictions if they live inside an agent

**Sub-model prediction overhead**: If both `RandomForest_small` and `Ensemble_v6` are registered in `ModelRegistry`, the random forest runs `predict()` twice (once standalone, once inside ensemble). This is intentional and negligible (~5us for a 24-tree forest). If standalone sub-model agents are not wanted, simply don't register sub-models individually -- only register the ensemble.

### 3. Mixed Feature Counts (Feature Prefix Invariant)

The ensemble can combine V5 models (42 features) with V6 models (55 features). Each sub-model receives `features[..model.n_features()]` inside `EnsembleModel::predict()`. This works because V5 features are a prefix of V6 features -- the first 42 are identical by design.

`EnsembleModel::n_features()` returns the max across all sub-models, ensuring the cache provides enough features.

**Invariant enforcement** (R5):
- `FeatureExtractor` trait documents the prefix invariant in its doc comment
- Types crate test asserts `FULL_FEATURE_NAMES[..42] == MARKET_FEATURE_NAMES`
- `EnsembleModel::predict()` includes `debug_assert!(features.len() >= model.n_features())`

### 4. Config-Driven Ensemble Composition

`ensemble_config.yaml` declares members and weights declaratively. The model factory loads each member by name from already-loaded models (sharing `Arc` instances):

```yaml
ensemble:
  name: "Ensemble_v6"
  members:
    - model: "RandomForest_small"
      weight: 1.0
    - model: "LinearModel_logistic_v6"
      weight: 0.8
    - model: "SvmLinear_linear_svc_v6"
      weight: 0.6
    - model: "GaussianNB_naive_bayes_v6"
      weight: 0.5
    - model: "GradientBoosted_fast"
      weight: 0.9
```

Weights can be:
- **Uniform**: All 1.0 (equal voting)
- **Accuracy-based**: Proportional to validation accuracy (auto-generated by Python training)
- **Learned**: V7.1 can optimize weights via reward signal

**Load-time validation** (R4): After parsing `ensemble_config.yaml`, validate:
- All member names exist in already-loaded models (fail with listing of missing + available names)
- weights > 0
- members >= 2
This is a hard error, not a warning.

### 5. Gaussian Naive Bayes for Ensemble Diversity

Added as a cheap baseline with fundamentally different inductive bias (feature independence assumption). Inference is ~50ns (no matrix multiply -- just 55 evaluations per class using precomputed reciprocals). Its errors are uncorrelated with tree and linear model errors, which is exactly what makes it a good ensemble member.

**Variance smoothing** (R3): sklearn uses `var_smoothing=1e-9` to prevent division by zero when a feature has zero variance for a class. The Rust implementation clamps variance at load time and precomputes `neg_half_log_var` and `inv_2var`, eliminating per-prediction `ln()` and division for zero runtime cost.

### 6. Modular Python Training Pipeline

Orchestrator + modules architecture instead of monolithic or fragmented scripts:
- `train_models.py` -- unified orchestrator, imports from per-model modules
- `train_trees.py` -- existing, refactored as importable module
- `train_linear.py` -- LogisticRegression training + JSON export
- `train_svm.py` -- LinearSVC training + JSON export
- `train_naive_bayes.py` -- GaussianNB training + JSON export

Each module is independently runnable AND importable. Shared data loading, labeling, and evaluation follow a consistent pattern.

**Import structure** (R7): Uses relative imports inside the `python/training/` package (`from .common import load_data`). CLI usage via `pyproject.toml` entry points (`qtg-train = "training.train_models:main"`).

---

## New Model Types

### LinearPredictor (`linear_predictor.rs`)

```rust
use serde::Deserialize;
use super::{ClassProbabilities, MlModel, softmax};

/// JSON deserialization: accept both naming conventions via serde alias.
#[derive(Debug, Deserialize)]
struct LinearPredictorJson {
    model_type: String,        // "linear_model" or "svm_linear"
    model_name: String,
    n_features: usize,
    n_classes: usize,          // 3
    classes: Vec<i32>,         // [-1, 0, 1]
    #[serde(alias = "coefficients")]
    weights: Vec<Vec<f64>>,    // [n_classes][n_features]
    #[serde(alias = "intercepts")]
    biases: Vec<f64>,          // [n_classes]
}

pub struct LinearPredictor {
    name: String,
    weights: Vec<Vec<f64>>,    // [3][n_features]
    biases: Vec<f64>,          // [3]
    n_features: usize,
}

impl LinearPredictor {
    pub fn from_json<P: AsRef<Path>>(path: P) -> Result<Self, String> {
        let json_str = std::fs::read_to_string(path.as_ref())
            .map_err(|e| format!("Failed to read {}: {}", path.as_ref().display(), e))?;
        Self::from_json_str(&json_str)
    }

    pub fn from_json_str(json: &str) -> Result<Self, String> {
        let parsed: LinearPredictorJson = serde_json::from_str(json)
            .map_err(|e| format!("JSON parse error: {}", e))?;

        // Validation
        if parsed.n_classes != 3 { return Err("Expected 3 classes".into()); }
        if parsed.weights.len() != 3 { return Err("Expected 3 weight rows".into()); }
        for (i, row) in parsed.weights.iter().enumerate() {
            if row.len() != parsed.n_features {
                return Err(format!("Row {} has {} weights, expected {}", i, row.len(), parsed.n_features));
            }
        }
        if parsed.biases.len() != 3 { return Err("Expected 3 biases".into()); }

        // Name prefix from model_type for log clarity
        let prefix = match parsed.model_type.as_str() {
            "svm_linear" => "SvmLinear",
            _ => "LinearModel",
        };
        let name = format!("{}_{}", prefix, parsed.model_name);
        Ok(Self { name, weights: parsed.weights, biases: parsed.biases, n_features: parsed.n_features })
    }
}

impl MlModel for LinearPredictor {
    fn predict(&self, features: &[f64]) -> ClassProbabilities {
        let mut scores = [0.0f64; 3];
        for class in 0..3 {
            scores[class] = self.weights[class].iter()
                .zip(features.iter())
                .map(|(w, f)| w * f)
                .sum::<f64>() + self.biases[class];
        }
        softmax(&scores)
    }

    fn name(&self) -> &str { &self.name }
    fn n_features(&self) -> usize { self.n_features }
}
```

**Latency target**: ~50ns (dot product of 55 features x 3 classes = 165 multiply-adds).

### GaussianNBPredictor (`gaussian_nb.rs`)

Uses variance smoothing (matching sklearn `var_smoothing=1e-9`) and precomputes `neg_half_log_var` and `inv_2var` at load time. This eliminates per-prediction `ln()` and division, and prevents `Inf`/`NaN` when variance is zero.

```rust
use serde::Deserialize;
use super::{ClassProbabilities, MlModel, softmax};

const VAR_SMOOTHING: f64 = 1e-9;

#[derive(Debug, Deserialize)]
struct GaussianNBJson {
    model_type: String,        // "gaussian_nb"
    model_name: String,
    n_features: usize,
    n_classes: usize,          // 3
    classes: Vec<i32>,         // [-1, 0, 1]
    class_log_prior: Vec<f64>, // [3] - log P(class)
    theta: Vec<Vec<f64>>,      // [3][n_features] - per-class means
    var: Vec<Vec<f64>>,        // [3][n_features] - per-class variances
}

pub struct GaussianNBPredictor {
    name: String,
    class_log_prior: [f64; 3],
    theta: Vec<Vec<f64>>,           // [3][n_features] means
    neg_half_log_var: Vec<Vec<f64>>, // precomputed -0.5 * ln(var)
    inv_2var: Vec<Vec<f64>>,         // precomputed 1/(2*var)
    n_features: usize,
}

impl GaussianNBPredictor {
    pub fn from_json_str(json: &str) -> Result<Self, String> {
        let parsed: GaussianNBJson = serde_json::from_str(json)
            .map_err(|e| format!("JSON parse error: {}", e))?;

        // Validation
        if parsed.n_classes != 3 { return Err("Expected 3 classes".into()); }
        if parsed.theta.len() != 3 || parsed.var.len() != 3 {
            return Err("Expected 3 rows for theta and var".into());
        }

        // Precompute with variance smoothing (matches sklearn var_smoothing=1e-9)
        let mut neg_half_log_var = Vec::with_capacity(3);
        let mut inv_2var = Vec::with_capacity(3);
        for class in 0..3 {
            let mut nhlv = Vec::with_capacity(parsed.n_features);
            let mut i2v = Vec::with_capacity(parsed.n_features);
            for i in 0..parsed.n_features {
                let var = parsed.var[class][i].max(VAR_SMOOTHING);
                nhlv.push(-0.5 * var.ln());
                i2v.push(1.0 / (2.0 * var));
            }
            neg_half_log_var.push(nhlv);
            inv_2var.push(i2v);
        }

        let name = format!("GaussianNB_{}", parsed.model_name);
        Ok(Self {
            name,
            class_log_prior: [parsed.class_log_prior[0], parsed.class_log_prior[1], parsed.class_log_prior[2]],
            theta: parsed.theta,
            neg_half_log_var,
            inv_2var,
            n_features: parsed.n_features,
        })
    }
}

impl MlModel for GaussianNBPredictor {
    fn predict(&self, features: &[f64]) -> ClassProbabilities {
        let mut log_probs = [0.0f64; 3];
        for class in 0..3 {
            log_probs[class] = self.class_log_prior[class];
            for i in 0..features.len().min(self.n_features) {
                // Two multiply-adds per feature, zero transcendental functions
                log_probs[class] += self.neg_half_log_var[class][i]
                    - (features[i] - self.theta[class][i]).powi(2) * self.inv_2var[class][i];
            }
        }
        softmax(&log_probs)
    }

    fn name(&self) -> &str { &self.name }
    fn n_features(&self) -> usize { self.n_features }
}
```

**Latency target**: ~50ns (55 multiply-add pairs per class, no transcendental functions at predict time).

**JSON from sklearn GaussianNB**:
```json
{
    "model_type": "gaussian_nb",
    "model_name": "naive_bayes_v6",
    "n_features": 55,
    "n_classes": 3,
    "classes": [-1, 0, 1],
    "class_log_prior": [-1.2, -0.8, -1.1],
    "theta": [[...55 means...], [...], [...]],
    "var": [[...55 variances...], [...], [...]]
}
```

---

## EnsembleModel (`ensemble_model.rs`)

```rust
use std::sync::Arc;
use super::{ClassProbabilities, MlModel};

pub struct EnsembleModel {
    name: String,
    models: Vec<Arc<dyn MlModel>>,
    weights: Vec<f64>,
    n_features: usize,  // max across sub-models
}

impl EnsembleModel {
    pub fn new(
        name: String,
        models: Vec<Arc<dyn MlModel>>,
        weights: Vec<f64>,
    ) -> Result<Self, String> {
        if models.len() < 2 {
            return Err("Ensemble must have at least 2 models".into());
        }
        if models.len() != weights.len() {
            return Err(format!(
                "models ({}) and weights ({}) must match",
                models.len(), weights.len()
            ));
        }
        if weights.iter().any(|&w| w <= 0.0) {
            return Err("All ensemble weights must be > 0".into());
        }
        let n_features = models.iter().map(|m| m.n_features()).max().unwrap();
        Ok(Self { name, models, weights, n_features })
    }

    /// Get the ensemble weights (V7.1 uses this for weight optimization).
    pub fn weights(&self) -> &[f64] {
        &self.weights
    }
}

impl MlModel for EnsembleModel {
    fn predict(&self, features: &[f64]) -> ClassProbabilities {
        let mut weighted = [0.0f64; 3];
        let mut total_weight = 0.0;

        for (model, &weight) in self.models.iter().zip(&self.weights) {
            let n = model.n_features().min(features.len());
            debug_assert!(features.len() >= model.n_features(),
                "Ensemble received {} features, sub-model '{}' needs {}",
                features.len(), model.name(), model.n_features());
            let probs = model.predict(&features[..n]);
            for i in 0..3 {
                weighted[i] += probs[i] * weight;
            }
            total_weight += weight;
        }

        if total_weight > 0.0 {
            for p in &mut weighted { *p /= total_weight; }
        }
        weighted
    }

    fn name(&self) -> &str { &self.name }
    fn n_features(&self) -> usize { self.n_features }
}
```

---

## Config-Driven Loading

### Model loader dispatch (`src/main.rs`)

All model types load into unified `MlModels` with a type tag. Adding a new model type = 1 match arm:

```rust
fn load_ml_models(models_dir: &Path) -> MlModels {
    let mut ml_models = MlModels::new();
    for entry in fs::read_dir(models_dir) {
        let model_type = parsed["model_type"].as_str();
        let load_result = match model_type {
            "decision_tree" => DecisionTree::from_json(&path).map(|m| ml_models.push("decision_tree", m)),
            "random_forest" => RandomForest::from_json(&path).map(|m| ml_models.push("random_forest", m)),
            "gradient_boosted" => GradientBoosted::from_json(&path).map(|m| ml_models.push("gradient_boosted", m)),
            "linear_model" | "svm_linear" => LinearPredictor::from_json(&path)
                .map(|m| ml_models.push(model_type, m)),
            "gaussian_nb" => GaussianNBPredictor::from_json(&path)
                .map(|m| ml_models.push("gaussian_nb", m)),
            other => {
                eprintln!("  Warning: Unknown model_type '{}' in {}", other, path.display());
                Ok(())
            }
        };
    }
    ml_models
}
```

### Ensemble loading (after individual models)

After loading all individual models, read `ensemble_config.yaml`, look up members by name from the `ModelRegistry` (sharing `Arc` instances), construct `EnsembleModel` with load-time validation:

```rust
fn load_ensemble(config_path: &Path, registry: &ModelRegistry) -> Result<EnsembleModel, String> {
    let config: EnsembleConfig = serde_yaml::from_str(&fs::read_to_string(config_path)?)?;

    // R4: Validate all member names exist
    let mut missing = Vec::new();
    for member in &config.members {
        if !registry.has_model(&member.model) {
            missing.push(member.model.clone());
        }
    }
    if !missing.is_empty() {
        let available: Vec<_> = registry.model_names().collect();
        return Err(format!(
            "Ensemble references missing models: {:?}\nAvailable: {:?}",
            missing, available
        ));
    }

    // Collect Arc<dyn MlModel> from registry
    let models: Vec<Arc<dyn MlModel>> = config.members.iter()
        .map(|m| registry.get_model(&m.model).unwrap())
        .collect();
    let weights: Vec<f64> = config.members.iter().map(|m| m.weight).collect();

    EnsembleModel::new(config.name, models, weights)
}
```

### MlModels struct (V6.2 unified, Phase 0 refactor)

```rust
// crates/simulation/src/agent_factory/ml_agents.rs
#[derive(Default)]
pub struct MlModels {
    models: Vec<(String, Arc<dyn MlModel>)>,  // (model_type, model)
}

impl MlModels {
    pub fn push(&mut self, model_type: &str, model: impl MlModel + 'static) {
        self.models.push((model_type.to_string(), Arc::new(model)));
    }
    pub fn has_models(&self) -> bool { !self.models.is_empty() }
    pub fn of_type(&self, model_type: &str) -> Vec<&Arc<dyn MlModel>> {
        self.models.iter().filter(|(t, _)| t == model_type).map(|(_, m)| m).collect()
    }
}
```

Spawning iterates `config.ml_agent_counts` (HashMap), groups loaded models by type, distributes agents round-robin across models of that type:

```rust
pub(crate) fn spawn_tree_agents(
    sim: &mut Simulation,
    config: &SimConfig,
    symbols: &[SymbolSpec],
    start_id: u64,
    models: &MlModels,
) -> (Vec<Box<dyn Agent>>, u64) {
    // Register all models for centralized prediction caching
    for (_, model) in models.all() {
        sim.register_ml_model_arc(model.clone());
    }

    let agent_config = MlAgentConfig { /* from SimConfig fields */ };
    let mut all_agents: Vec<Box<dyn Agent>> = Vec::new();
    let mut next_id = start_id;

    // Spawn agents per model type based on config counts
    for (model_type, count) in &config.ml_agent_counts {
        let model_names: Vec<String> = models.of_type(model_type)
            .iter().map(|m| m.name().to_string()).collect();
        if model_names.is_empty() { continue; }
        let agents = spawn_ml_agents(&model_names, *count, next_id, agent_config.clone());
        next_id += agents.len() as u64;
        all_agents.extend(agents);
    }
    (all_agents, next_id)
}
```

### Default agent counts (SimConfig)

```rust
ml_agent_counts: HashMap::from([
    ("decision_tree".into(), 400),
    ("random_forest".into(), 100),
    ("gradient_boosted".into(), 200),
    // V6.2 additions:
    ("linear_model".into(), 100),
    ("svm_linear".into(), 100),
    ("gaussian_nb".into(), 50),
    ("ensemble".into(), 50),
]),
```

---

## Python Training Pipeline

### Script Architecture: Orchestrator + Modules

Move training scripts from flat `scripts/` into a proper Python package at `python/training/`. This separates Python from Rust, enables clean imports between modules, and prepares for V6.5 PyO3 bindings (which will live at `python/quant_gym/`).

```
python/
  training/
    __init__.py            # makes it an importable package
    train_models.py        # orchestrator - imports from modules, runs all
    train_trees.py         # existing - refactored as importable module
    train_linear.py        # NEW - LogisticRegression training + export
    train_svm.py           # NEW - LinearSVC training + export
    train_naive_bayes.py   # NEW - GaussianNB training + export
    common.py              # shared: data loading, labeling, evaluation, export helpers
    config.yaml            # training config (moved from scripts/)
  analysis/
    analyze_shap.py        # SHAP analysis (moved from scripts/)
    check_parquet.py       # data validation (moved from scripts/)
  pyproject.toml           # package metadata + dependencies (sklearn, polars, etc.)
```

Each module is independently runnable via entry points AND importable by `train_models.py` via relative imports (`from .common import load_data, prepare_features`).

### pyproject.toml

```toml
[project]
name = "qtg-training"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = ["scikit-learn", "polars", "pyyaml", "shap"]

[project.scripts]
qtg-train = "training.train_models:main"
qtg-train-linear = "training.train_linear:main"
qtg-train-trees = "training.train_trees:main"
qtg-train-nb = "training.train_naive_bayes:main"
```

### train_config.yaml (extended sections)

```yaml
# Existing: data, labels, decision_trees, random_forests, gradient_boosted, shap

linear_models:
  - name: logistic_v6
    solver: lbfgs
    max_iter: 1000
    C: 1.0

svm_models:
  - name: linear_svc_v6
    max_iter: 2000
    C: 1.0

naive_bayes:
  - name: naive_bayes_v6
    # GaussianNB has no hyperparameters to tune

ensemble:
  name: ensemble_v6
  mode: auto   # weights = validation accuracy of each trained model
```

### train_linear.py

```python
"""Train LogisticRegression and export JSON for Rust LinearPredictor inference."""
from sklearn.linear_model import LogisticRegression

def train_linear_model(X_train, y_train, X_test, y_test, feature_names, config, name):
    clf = LogisticRegression(
        multi_class="multinomial",
        solver=config.get("solver", "lbfgs"),
        max_iter=config.get("max_iter", 1000),
        C=config.get("C", 1.0),
        class_weight='balanced',
        random_state=42,
    )
    clf.fit(X_train, y_train)

    result = {
        "model_type": "linear_model",
        "model_name": name,
        "n_features": X_train.shape[1],
        "n_classes": 3,
        "classes": [-1, 0, 1],
        "coefficients": clf.coef_.tolist(),
        "intercepts": clf.intercept_.tolist(),
        "metadata": { ... }
    }
    return clf, result
```

### train_svm.py

```python
"""Train LinearSVC and export JSON for Rust LinearPredictor inference."""
from sklearn.svm import LinearSVC

def train_svm_model(X_train, y_train, X_test, y_test, feature_names, config, name):
    clf = LinearSVC(
        multi_class="crammer_singer",
        max_iter=config.get("max_iter", 2000),
        C=config.get("C", 1.0),
        class_weight='balanced',
        random_state=42,
    )
    clf.fit(X_train, y_train)

    result = {
        "model_type": "svm_linear",
        "model_name": name,
        "n_features": X_train.shape[1],
        "n_classes": 3,
        "classes": [-1, 0, 1],
        "weights": clf.coef_.tolist(),
        "biases": clf.intercept_.tolist(),
        "metadata": { ... }
    }
    return clf, result
```

### train_naive_bayes.py

```python
"""Train GaussianNB and export JSON for Rust GaussianNBPredictor inference."""
from sklearn.naive_bayes import GaussianNB
import numpy as np

def train_naive_bayes_model(X_train, y_train, X_test, y_test, feature_names, config, name):
    clf = GaussianNB()
    clf.fit(X_train, y_train)

    result = {
        "model_type": "gaussian_nb",
        "model_name": name,
        "n_features": X_train.shape[1],
        "n_classes": 3,
        "classes": [-1, 0, 1],
        "class_log_prior": np.log(clf.class_prior_).tolist(),
        "theta": clf.theta_.tolist(),
        "var": clf.var_.tolist(),
        "metadata": { ... }
    }
    return clf, result
```

### train_models.py (orchestrator)

```python
"""Unified training orchestrator. Imports from per-model modules."""
from .train_trees import train_all_trees
from .train_linear import train_all_linear
from .train_svm import train_all_svm
from .train_naive_bayes import train_all_naive_bayes
from .common import load_config, load_and_split

def main():
    config = load_config(args.config)
    X_train, X_test, y_train, y_test, feature_names = load_and_split(config)

    trained = {}
    trained.update(train_all_trees(X_train, y_train, X_test, y_test, feature_names, config))
    trained.update(train_all_linear(X_train, y_train, X_test, y_test, feature_names, config))
    trained.update(train_all_svm(X_train, y_train, X_test, y_test, feature_names, config))
    trained.update(train_all_naive_bayes(X_train, y_train, X_test, y_test, feature_names, config))

    generate_ensemble_config(trained, config, output_dir)
```

### Ensemble config auto-generation

After all models trained, auto-generate `ensemble_config.yaml` with validation accuracy as weights:

```python
def generate_ensemble_config(trained_models, config, output_dir):
    members = []
    for model_key, (clf, accuracy) in trained_models.items():
        members.append({"model": model_key, "weight": float(accuracy)})

    ensemble_config = {
        "ensemble": {
            "name": config.get("ensemble", {}).get("name", "ensemble_v6"),
            "members": members,
        }
    }
    with open(output_dir / "ensemble_config.yaml", "w") as f:
        yaml.dump(ensemble_config, f)
```

---

## Feature Engineering Experiment Loop

**Core principle**: Features are the stable API between Rust extraction and Python training. All model types use the same feature set. Features and models iterate in parallel.

### Loop

```
1. HYPOTHESIZE  - identify candidate signal, define computation + neutral + range
2. IMPLEMENT    - add to group_extractors.rs + FeatureRegistry + FullFeatures
3. RECORD       - cargo run --headless-record --full-features --ticks 50000
4. TRAIN        - python train_models.py (ALL model types on updated features)
5. EVALUATE     - ablation, SHAP, per-model accuracy, ensemble sim P&L
6. DECIDE       - keep if net-positive across model types + sim P&L
7. CONVERGE     - freeze feature set for V6.4 gym observation space
```

### Evaluation criteria (step 5)

- **Ablation**: `FullFeatures.disable_group(NewGroup)` -> retrain all models -> accuracy delta
- **SHAP**: Per-feature importance (trees, via TreeExplainer). Cross-reference with ablation.
- **Per-model accuracy**: Did all model types improve, or only some? Features that help trees but hurt linear models may indicate interaction effects.
- **Sim P&L**: Run full sim with ensemble, compare against previous best. Use 3+ seeds for significance.
- **Cross-model agreement**: When diverse models agree, confidence is higher. Measure ensemble agreement rate before/after new features.

### Why parallel model+feature iteration works

Different model types have different sensitivity to features:
- **Trees**: Discover non-linear interactions; robust to irrelevant features (just ignore them)
- **Linear**: Sensitive to multicollinearity; new features must add orthogonal signal
- **Naive Bayes**: Assumes independence; cross-features (e.g., `sentiment_price_gap`) may hurt it
- **Ensemble**: Benefits from member diversity; a feature that helps one model type but not others still helps the ensemble

Running all model types in each iteration gives richer signal about feature quality than trees alone.

### Feature group extension pattern

1. `types/features.rs`: Add `FeatureGroup` variant, descriptors, names, neutrals, bump `N_FULL_FEATURES`
2. `group_extractors.rs`: Add `pub fn extract_new_group(symbol, ctx, buf)`
3. `full_features.rs`: Add `if self.group_enabled(NewGroup) { extract_new_group(...); }`
4. Compile-time assertions auto-verify schema consistency
5. `SmallVec<[f64; 64]>` handles up to 64 features inline; bump capacity if exceeding

### Ablation CLI

Add `--ablate <group>` flag for quick marginal-contribution testing:
```
cargo run -- --headless --full-features --ablate Microstructure --ticks 10000
```

---

## Files Summary

### Phase 0 refactored files (DONE)
| File | Action |
|------|--------|
| `crates/agents/src/tier1/ml/ml_agent.rs` | CREATE -- non-generic MlAgent (replaces tree_agent.rs) |
| `crates/agents/src/tier1/ml/mod.rs` | MODIFY -- new module declaration, remove type aliases, zero-alloc softmax, feature prefix invariant docs |
| `crates/agents/src/tier1/mod.rs` | MODIFY -- update re-exports to MlAgent/MlAgentConfig |
| `crates/agents/src/lib.rs` | MODIFY -- update crate-level re-exports |
| `crates/simulation/src/agent_factory/ml_agents.rs` | REWRITE -- unified MlModels, HashMap-driven spawning |
| `crates/simulation/src/sim_config.rs` | MODIFY -- ml_agent_counts HashMap, single .ml_agents() builder |
| `crates/simulation/src/runner.rs` | MODIFY -- add register_ml_model_arc() for Arc-wrapped models |
| `src/main.rs` | MODIFY -- unified load_ml_models() dispatch |

### New Rust files (Phase 1)
| File | Action |
|------|--------|
| `crates/agents/src/tier1/ml/linear_predictor.rs` | CREATE -- LinearPredictor (unified LR + SVC via serde alias) |
| `crates/agents/src/tier1/ml/gaussian_nb.rs` | CREATE -- GaussianNBPredictor (variance smoothing, precomputed) |
| `crates/agents/src/tier1/ml/ensemble_model.rs` | CREATE -- EnsembleModel (MlModel impl, weighted voting, validation) |

### Modified Rust files (Phase 1)
| File | Action |
|------|--------|
| `crates/agents/src/tier1/ml/mod.rs` | MODIFY -- add `mod linear_predictor; mod gaussian_nb; mod ensemble_model;` + exports |
| `crates/agents/src/tier1/mod.rs` | MODIFY -- export LinearPredictor, GaussianNBPredictor, EnsembleModel |
| `crates/agents/src/lib.rs` | MODIFY -- export new types at crate level |
| `src/main.rs` | MODIFY -- extend load_ml_models() dispatch + ensemble loading from YAML |

### New Python files (Phase 2)
| File | Action |
|------|--------|
| `python/training/__init__.py` | CREATE -- package init |
| `python/training/train_models.py` | CREATE -- orchestrator with relative imports |
| `python/training/train_linear.py` | CREATE -- LogisticRegression training + JSON export |
| `python/training/train_svm.py` | CREATE -- LinearSVC training + JSON export |
| `python/training/train_naive_bayes.py` | CREATE -- GaussianNB training + JSON export |
| `python/training/common.py` | CREATE -- shared data loading, labeling, evaluation helpers |
| `python/pyproject.toml` | CREATE -- package metadata + entry points + dependencies |

### New config files
| File | Action |
|------|--------|
| `models/ensemble_config.yaml` | CREATE -- declarative ensemble composition (auto-generated by training) |

### Moved files (Phase 2)
| File | Action |
|------|--------|
| `scripts/train_trees.py` | MOVE to `python/training/train_trees.py` -- refactor as importable module |
| `scripts/train_config.yaml` | MOVE to `python/training/config.yaml` -- add linear_models, svm_models, naive_bayes, ensemble sections |
| `scripts/analyze_shap.py` | MOVE to `python/analysis/analyze_shap.py` |
| `scripts/check_parquet.py` | MOVE to `python/analysis/check_parquet.py` |

---

## V6.4/V7 Feed-Forward

- **V6.4 Gym**: Ensemble agents become smart background agents the RL agent must compete against. Observation space = CanonicalFeatures (28 SHAP-validated, frozen after V6.3). ML cache features reusable for gym observations (Option A in 6.4 plan). Note: correlated ensemble agents may flood the order book -- may need reduced ensemble count or diversified threshold configs.
- **V7.1 RL**: Ensemble P&L = performance floor. Ensemble weights become learnable via reward optimization. RL agent can use ensemble probabilities as input features (teacher-student architecture). V7 can reconstruct `EnsembleModel` with new weights via `ModelRegistry.register()` (which already overwrites by name). `weights()` accessor provided.
- **V7.2 Deep RL (ONNX)**: A neural net model implementing `MlModel` plugs into the same unified `MlModels` / `ModelRegistry` / `MlAgent` pipeline with zero structural changes -- just a new match arm in `load_ml_models()`. This validates the R2 design.

---

## Verification

1. **Unit tests**: LinearPredictor load from both JSON conventions (coefficients/intercepts and weights/biases), predictions sum to 1.0
2. **Unit tests**: GaussianNBPredictor load from JSON, predictions sum to 1.0, variance=0 produces valid probabilities (not NaN/Inf)
3. **Ensemble test**: Create EnsembleModel with mock sub-models of known outputs, verify weighted voting arithmetic
4. **Mixed features test**: EnsembleModel with V5 (42) and V6 (55) sub-models, verify feature slicing
5. **Ensemble validation**: Missing member name produces clear error message listing available models
6. **Integration test**: Run simulation with ensemble agents for 5000 ticks, verify they trade and have non-zero P&L
7. **Python round-trip**: Train model in Python -> export JSON -> load in Rust -> verify identical predictions on 10 test vectors (tolerance 1e-6)
8. **Performance benchmarks**:
   - LinearPredictor: target < 100ns (55 features)
   - GaussianNBPredictor: target < 100ns (55 features)
   - EnsembleModel (5 sub-models): target < 30us
9. **Training pipeline**: `qtg-train` end-to-end, produces all JSON files + `ensemble_config.yaml`
10. **Ablation**: Disable one feature group, verify ensemble P&L changes (confirms features contribute)
11. **Phase 0 regression**: `cargo test --workspace` passes, headless sim produces identical output (same seed)
